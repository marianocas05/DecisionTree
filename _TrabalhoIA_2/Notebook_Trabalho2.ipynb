{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FxTtVp5Fl_O",
        "toc-hr-collapsed": false
      },
      "source": [
        "# TRABALHO #2 — Grupo 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdrAbnFIFl_Q",
        "toc-hr-collapsed": false
      },
      "source": [
        " **Tópico: Decision Trees**\n",
        "\n",
        "Membros:\n",
        "\n",
        " - Mariana Filipa Ribeiro Ferreira (up202205006)\n",
        " - Raquel Barbosa Ferreira Alves   (up202206827)\n",
        " - Gonçalo Reimão Silva da Luz     (up202205522)\n",
        "\n",
        " Vídeo:\n",
        " - https://drive.google.com/file/d/1VsTrIsfLVJjSS7ZkxIvVFV_YH-9eV3Pb/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "from math import log2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "rows_destruidas = 0\n",
        "\n",
        "def discValues(data):\n",
        "    num_bins = int(np.log2(len(data)) + 1)\n",
        "    bin_intervals = {}\n",
        "    \n",
        "    for column in data.columns[1:]:\n",
        "        if pd.api.types.is_numeric_dtype(data[column]):  # Apenas discretiza colunas numéricas\n",
        "            # Discretiza os valores e obtém os bins\n",
        "            discretized_values, bins = pd.cut(data[column], bins=num_bins, labels=False, retbins=True)\n",
        "            data[column] = discretized_values\n",
        "            bin_intervals[column] = bins\n",
        "    \n",
        "    return data, bin_intervals\n",
        "\n",
        "dataset_paths = {\n",
        "    'restaurant': r\"restaurant.csv\",\n",
        "    'weather': r\"weather.csv\",\n",
        "    'iris': r\"iris.csv\",\n",
        "    'connect4': r\"connect4_2.csv\", # connect4 mas com a primeira linha\n",
        "    'new': r\"new.csv\"              # alterar new para nome do ficheiro\n",
        "}\n",
        "\n",
        "while True:\n",
        "    choice = input(\"Choose the dataset: \")\n",
        "\n",
        "    if choice in dataset_paths:\n",
        "        if choice == 'restaurant': # trocar os none para NONE\n",
        "            csv_data = pd.read_csv('restaurant.csv', dtype={'Pat': str}, na_filter=False)\n",
        "            csv_data['Pat'] = csv_data['Pat'].apply(lambda x: 'NONE' if x == 'None' else x)\n",
        "            csv_data.to_csv('restaurant.csv', index=False)\n",
        "        else:\n",
        "            csv_data = pd.read_csv(dataset_paths[choice])\n",
        "\n",
        "        headers = csv_data.columns.tolist()\n",
        "        dataset = csv_data.values.tolist()\n",
        "\n",
        "        num_items = len(dataset[0])\n",
        "        cleaned_dataset = []\n",
        "\n",
        "        csv_data, bin_intervals = discValues(csv_data)\n",
        "        \n",
        "        for row in dataset:\n",
        "            if len(row) == num_items:\n",
        "                cleaned_dataset.append(row)\n",
        "            else:\n",
        "                rows_destruidas += 1\n",
        "\n",
        "        print(\"Dataset loaded, cleaned, and discretized successfully.\")\n",
        "        print(f\"Number of disregarded rows: {rows_destruidas}\")\n",
        "        print(\"- - - - - -\")\n",
        "        for column, bins in bin_intervals.items():\n",
        "            print(f\"{column}: {bins}\")\n",
        "        print(\"- - - - - -\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid choice. Please choose a valid dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Três bibliotecas são importadas no início do ficheiro:\n",
        " - A biblioteca \"pandas\" é usada para manipulação e analise de dados.\n",
        " - A biblioteca \"numpy\" é usada para operações numéricas (em específico, na função \"discValues\").\n",
        " - Da biblioteca \"collections\", são importados \"Counter\" e \"collections\", que são utilizados para a contagem de elementos e a criação de dicionários.\n",
        " - Da biblioteca \"math\" é importado \"log2\", necessário para calcular a entropia.\n",
        "\n",
        "A variável \"choice\" requer input do utilizador, de um dos dataset especifícados no dicionário \"dataset_paths\". Estes dicionário mapeia uma palavra para o ficheiro associado (exemplo: a chave \"restaurant\" indica o ficheiro \"restaurant.csv\" que contém o dataset associado).\n",
        "\n",
        "Se a escolha guardada em \"choice\" for inválida, é impressa uma mensagem de erro. Se for válida, o programa prossegue e ficheiro escolhido é lido pela função \"pd.read_csv()\", que cria a DataFrame \"csv_data\" com a informação.\n",
        "\n",
        "A variável \"headers\" recebe um array com os nomes dos atríbutos do DataFrame criado, enquanto a variável \"dataset\" converte o DataFrame num array de arrays, onde cada sub-array representa uma linha do dataset original.\n",
        "\n",
        "De seguida, o dataset é analisado e, através da função \"discValues\". Esta função discretiza os valores numéricos usando a fórmula de Sturges. De seguida, se alguma fila apresentar falhas, esta é apagada, o que será contado na variável \"rows_destruidas\".\n",
        "\n",
        "De seguida, é impresso o nnúmero de linhas eliminadas, e os bins criados pela função \"discValues\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def entropy(data):\n",
        "    total = len(data)\n",
        "    counts = Counter(row[-1] for row in data)\n",
        "    return -sum((count/total) * log2(count/total) for count in counts.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função \"entropy\" recebe o dataset e calcula a sua entropia associada.\n",
        "\n",
        "A variável \"total\" contém o número de linhas do dataset recebido. A variável \"count\" conta cada occorência de cada classe na última coluna. Com isso, a função retorna o valor da entropia através da fórmula:\n",
        " - -sum((count/total) * log2(count/total) for count in counts.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Information Gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def information_gain(data, attribute_index):\n",
        "    total = len(data)\n",
        "    subsets = defaultdict(list)\n",
        "    \n",
        "    for row in data:\n",
        "        subsets[row[attribute_index]].append(row)\n",
        "    \n",
        "    weighted_entropy = sum((len(subset)/total) * entropy(subset) for subset in subsets.values())\n",
        "    return entropy(data) - weighted_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função \"information_gain\" recebe o dataset e o index do atríbuto cujo ganho de informação queremos determinar.\n",
        "\n",
        "A variável \"total\" contém o número de linhas do dataset recebido. A variável \"subsets\" contém um dicionário de um subconjunto do dataset, dividido pelos valores únicos do atributo especificado (gerado no loop seguinte).\n",
        "\n",
        "De seguida, é calculada a entropia de cada subconjunto e, ao subtrair essa à entropia do dataset todo, temos o ganho de informação do atributo especfico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def best_attribute(data, attributes):\n",
        "    gains = [(attr, information_gain(data, index)) for index, attr in enumerate(attributes)]\n",
        "    return max(gains, key=lambda x: x[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função \"best_attribute\" recebe o dataset e todos os seus atributos, calculando (com chamadas à funçao anterior) qual dos atributos do dataset tem o maior ganho de informação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Entropy of the dataset:\", entropy(dataset))\n",
        "print(\"Best attribute to split on:\", best_attribute(dataset, headers[1:-1]))\n",
        "print(\"- - - - - -\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class \"Node\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, attribute=None, value=None, result=None, counter=None, branches=None):\n",
        "        self.attribute = attribute\n",
        "        self.value = value\n",
        "        self.result = result\n",
        "        self.counter = counter\n",
        "        self.branches = branches if branches is not None else {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "É definida uma estrutura \"Node\" que representa um nó na árvore de decisão. Cada nó tem associado um atributo \"attributte\", valor \"value\", resultado \"result, contador \"counter\", e ramos \"branches (que se não for inicializado fica um dicionário vazio)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_tree(data, attributes):\n",
        "    if not data:\n",
        "        return None\n",
        "    \n",
        "    class_counts = Counter(row[-1] for row in data)\n",
        "    if len(class_counts) == 1:\n",
        "        return Node(result=list(class_counts.keys())[0], counter=len(data))\n",
        "    if not attributes:\n",
        "        result = class_counts.most_common(1)[0][0]\n",
        "        return Node(result=result, counter=len(data))\n",
        "    best_attr, best_gain = best_attribute(data, attributes)\n",
        "    best_attr_index = headers.index(best_attr)\n",
        "    root = Node(attribute=best_attr)\n",
        "    partitions = defaultdict(list)\n",
        "    for row in data:\n",
        "        partitions[row[best_attr_index]].append(row)\n",
        "    \n",
        "    for attr_value, subset in partitions.items():\n",
        "        remaining_attrs = [attr for attr in attributes if attr != best_attr]\n",
        "        # int --> string\n",
        "        if isinstance(attr_value, int):\n",
        "            attr_value = str(attr_value)\n",
        "        branch = build_tree(subset, remaining_attrs)\n",
        "        root.branches[str(attr_value)] = branch  # --> string\n",
        "    return root\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função \"build_tree\" recebe o dataset e os seus atributos. Se o dataset for vazio, retorna \"None\". Este é o caso base da função \"build_tree\", que constroi a árvore de decisão de modo recursivo.\n",
        "\n",
        "Se o dataset não for vazio, a variável \"class_counts\" conta o número de ocorrências de cada classe no dataset. Se todas as linhas do dataset pertencerem à mesma class, um nó filho é criado com essa classe como \"result\" e o número de filas como \"counter\".\n",
        "\n",
        "Se não existirem mais atributos, um nó filho é criado com a classe mais comum como \"result\" e o número de filas como \"counter\".\n",
        "\n",
        "De seguida, é encontrado o melhor atributo para dividir a árvore através da função \"best_attribute\" e o seu index associado. Esse atributo será a raiz da árvore de decisão criada. Um dicionário é inicializado para guardar as partições do dataset e, para cada partição, a função constroi recursivamente a árvore de decisão com os métodos acima mencionados.\n",
        "\n",
        "A variável \"attributes\" cria a lista que será utilizada para construir a árvore de decisão (que contém o \"header\" do ficheiro .csv dado, excluindo a primera e última coluna). Esta função retorna a raiz da árvore. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes = headers[1:-1]\n",
        "decision_tree = build_tree(dataset, attributes)\n",
        "\n",
        "def print_tree(node, indent=\"   \"):\n",
        "    if node.result is not None:\n",
        "        print(f\"{indent}{node.result}: (Counter: {node.counter})\")\n",
        "    else:\n",
        "        print(f\"{indent}<{node.attribute}>\")\n",
        "        for value, branch in node.branches.items():\n",
        "            print(f\"{indent}{value}:\")\n",
        "            print_tree(branch, indent + \"    \")\n",
        "\n",
        "print_tree(decision_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A variável \"attributes\" excluí a primeira e última colunas de \"headers\". Com esta variável e a variável \"dataset\", usamos a função \"build_tree\" para construir a árvore de decisão correspondente, que fica disponível a partir da variável \"decision_tree\".\n",
        "\n",
        "A função \"print_tree\" imprime recursivamente a árvore de decisão. Para folhas, imprime o resultado e o counter associado. Para nós de decisão, imprime o atributo associado e, recursivamente, cada ramo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict Single"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PredictSingle(instance, decision_tree):\n",
        "    if decision_tree.result is not None:\n",
        "        return decision_tree.result\n",
        "    \n",
        "    attribute = decision_tree.attribute\n",
        "    attr_value = instance.get(attribute)\n",
        "\n",
        "    if (attr_value is None) or (attr_value not in list(decision_tree.branches.keys())):\n",
        "        next\n",
        "    else:\n",
        "        return PredictSingle(instance, decision_tree.branches[attr_value])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função \"PredictSingle\" é uma função recursiva que recebe uma potencial instancia de um cenário, e a árvore de decisão associada com esse mesmo ficheiro.\n",
        "\n",
        "A função começa por verificar se o nó atual da árvore de decisão contém um \"result\". Se sim, esse resultado é retornado diretamente. Se não, então a função atravessa a árvore recursivamente, passando para os nós filhos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_file(input_file, decision_tree):\n",
        "    predictions = []\n",
        "    \n",
        "    with open(input_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        instance = {}\n",
        "        attributes = line.strip().split(',')\n",
        "        for index, attr_value in enumerate(attributes):\n",
        "            instance[headers[index+1]] = attr_value\n",
        "        \n",
        "        predicted_class = PredictSingle(instance, decision_tree)\n",
        "        predictions.append(predicted_class)\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "# '''\n",
        "print(\"- - - - - -\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função \"predict_file\" lê um ficheiro que contém várias instâncias de um cenário e, utilizando a função \"PredictSingle\", verifica cada instância e retorna uma lista com as classes previstas para cada uma dessas instancias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if choice == 'restaurant':\n",
        "    predictions = predict_file(r\"test1.csv\", decision_tree)\n",
        "    print(f\"Predicted classes: \", predictions)\n",
        "\n",
        "elif choice == 'weather':\n",
        "    predictions = predict_file(r\"test2.csv\", decision_tree)\n",
        "    print(f\"Predicted classes: \", predictions)\n",
        "\n",
        "elif choice == 'iris':\n",
        "    predictions = predict_file(r\"test3.csv\", decision_tree)\n",
        "    print(f\"Predicted classes: \", predictions)\n",
        "\n",
        "elif choice == \"connect4\":\n",
        "    instance = {\n",
        "    'X1': 'b',\n",
        "    'X2': 'b',\n",
        "    'X3': 'b',\n",
        "    'X4': 'b',\n",
        "    'X5': 'b',\n",
        "    'X6': 'b',\n",
        "    'X7': 'b',\n",
        "    'X8': 'b',\n",
        "    'X9': 'b',                #b,b,b,b,b,b,b,b,b,b,b,b,x,o,b,b,b,b,x,o,x,o,x,o,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,b,win\n",
        "    'X10': 'b',\n",
        "    'X11': 'b',\n",
        "    'X12': 'b',\n",
        "    'X13': 'x',\n",
        "    'X14': 'o',\n",
        "    'X15': 'b',\n",
        "    'X16': 'b',\n",
        "    'X17': 'b',\n",
        "    'X18': 'b',\n",
        "    'X19': 'x',\n",
        "    'X20': 'o',\n",
        "    'X21': 'x',\n",
        "    'X22': 'o',\n",
        "    'X23': 'x',\n",
        "    'X24': 'o',\n",
        "    'X25': 'b',\n",
        "    'X26': 'b',\n",
        "    'X27': 'b',\n",
        "    'X28': 'b',\n",
        "    'X29': 'b',\n",
        "    'X30': 'b',\n",
        "    'X31': 'b',\n",
        "    'X32': 'b',\n",
        "    'X33': 'b',\n",
        "    'X34': 'b',\n",
        "    'X35': 'b',\n",
        "    'X36': 'b',\n",
        "    'X37': 'b',\n",
        "    'X38': 'b',\n",
        "    'X39': 'b',\n",
        "    'X40': 'b',\n",
        "    'X41': 'b',\n",
        "    'X42': 'b'\n",
        "    }\n",
        "    predictions = PredictSingle(instance, decision_tree)\n",
        "    print(f\"Predicted classes: \", predictions)\n",
        "\n",
        "elif choice == 'new':\n",
        "    predictions = predict_file(r\"test_new.csv\", decision_tree)   #colocar teste para o ficheiro new\n",
        "    print(f\"Predicted classes: \", predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data(df):\n",
        "    data_with_labels = df.values.tolist()\n",
        "    train_data, test_data = train_test_split(data_with_labels, test_size=0.3)\n",
        "    X_test = [row[1:-1] for row in test_data]\n",
        "    y_test = [row[-1] for row in test_data]\n",
        "    y_test = [str(label) for label in y_test]\n",
        "    return train_data, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função \"prepare_data\" é utilizada para preparar os dados para o treino e teste da árvore criada. A função retorna train_data (os dados de treino), X_test (os atributos usados para o teste) e y_test (as classes do conjunto de teste)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_predictions(instances, decision_tree):\n",
        "    predictions = []\n",
        "    for instance in instances:\n",
        "        prediction = PredictSingle(instance, decision_tree)\n",
        "        predictions.append(prediction)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esta função faz previsões para uma lista de instâncias usando a árvore de decisão. O seu objetivo é prever classes para um conjunto de dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(df, test_size):\n",
        "    train_data, X_test, y_test = prepare_data(df)\n",
        "    attributes = headers[1:-1]\n",
        "    train_tree = build_tree(train_data, attributes)\n",
        "\n",
        "    instances = [{attribute: value for attribute, value in zip(attributes, instance)} for instance in X_test]\n",
        "\n",
        "    predictions = make_predictions(instances, train_tree)\n",
        "    predictions = [str(pred) for pred in predictions]\n",
        "\n",
        "    accuracy = sum([1 for i in range(len(y_test)) if y_test[i] == predictions[i]]) / len(y_test)\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    balanced_accuracy = balanced_accuracy_score(y_test, predictions)\n",
        "    print(f\"Balanced Accuracy: {balanced_accuracy:.2f}\")\n",
        "\n",
        "    print(str(predictions) + \"\\n\")\n",
        "    print(str(y_test) + \"\\n\")\n",
        "    predictions_correct = []\n",
        "    for true_label, predicted_label in zip(y_test, predictions):\n",
        "        if true_label == predicted_label:\n",
        "            predictions_correct.append(1)\n",
        "        else:\n",
        "            predictions_correct.append(0)\n",
        "    predictions_total = len(predictions_correct)\n",
        "    correct_count = sum(predictions_correct)\n",
        "    incorrect_count = predictions_total - correct_count\n",
        "\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_test, predictions, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_test, predictions, average='macro', zero_division=0)\n",
        "    \n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "\n",
        "    # gráfico de barras\n",
        "    plt.bar(['Corretas', 'Incorretas'], [correct_count, incorrect_count], color=['green', 'red'])\n",
        "    plt.title('Previsões Corretas vs. Previsões Incorretas')\n",
        "    plt.xlabel('Tipo de Previsão')\n",
        "    plt.ylabel('Número de Previsões')\n",
        "    plt.show()\n",
        "\n",
        "print(\"- - - - - -\")\n",
        "evaluate_model(csv_data, test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função \"evaluate_model\" avalia o desempenho de uma árvore de decisão usando um conjunto de dados fornecido. Os argumentos passados à função são o dataframe com as informações necessárias e o tamanho desejado para o conjunto de teste.\n",
        "Começa por preparar os dados para que os possa usar para fazer previsões. Depois de feitas, calcula a precisão com o qual a árvore acertou na classe, comparando predictions com y_test. \n",
        "Por fim, constrói um gráfico de barras que ilustra o número de previsões corretas e incorretas.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "toc-autonumbering": true
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
